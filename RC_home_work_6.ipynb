{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMBdGcvjC4Ji"
   },
   "source": [
    "# Home work 6. Двухуровневые модели рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Aur99NsC4Jm",
    "outputId": "9b9a338b-a52f-4253-9694-ac431b62eefc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaomi\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys, itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "from lightfm import LightFM\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# from src import MainRecommender, prefilter_items, precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.metrics import precision_at_k, recall_at_k, reciprocal_rank_at_k, ndcg_at_k, ap_k, ap_k_2 \n",
    "from src.recommenders import MainRecommender\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vso_erSdC4Jo",
    "outputId": "da20dbf1-3086-4fd6-ac92-f7653d7f9f71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Lesson_2/retail_train.csv')\n",
    "item_features = pd.read_csv('../Lesson_2/product.csv')\n",
    "user_features = pd.read_csv('../Lesson_2/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zcnV3l4XC4Jp",
    "outputId": "d58f889c-0671-4bb9-b2b6-2dc2e8c24fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 5001\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2375, 1364, 1172, ...,  363, 1721, 1480], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_lvl_1[\"user_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "729d4287bb794971802d9da5e141f10a",
      "32375ef613474af6a0fcadb9255eb835"
     ]
    },
    "id": "zgYXRQ0lC4Jq",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d9ea41ae-3b4d-41b4-fc46-90868ebb9894",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaomi\\AppData\\Roaming\\Python\\Python39\\site-packages\\implicit\\utils.py:33: UserWarning: Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a848aded41e644cb8b3b98402c198cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab32e54559614f999bb52accbf7ddf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8090521, 5569230, 8090537, 983584, 844179]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_als_recommendations(125, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1029743, 1106523, 5569230, 916122, 844179]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_own_recommendations(125, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999999, 8090521, 913210, 5573394, 8090556]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_items_recommendation(125, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1029743, 1029743, 1029743, 1029743, 1029743]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_users_recommendation(345, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqs9Sw_YC4Jt"
   },
   "source": [
    "### Задание 1\n",
    "\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "- Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?  \n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "frt2RzDWC4Jt",
    "outputId": "7c594abf-4a34-406b-9897-8bfbddf69a93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "result_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xM5W4mU4C4Jt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 20\n",
      "als is ready.\n",
      "own is ready.\n",
      "similar_items_recommendation is ready.\n",
      "n = 50\n",
      "als is ready.\n",
      "own is ready.\n",
      "similar_items_recommendation is ready.\n",
      "n = 100\n",
      "als is ready.\n",
      "own is ready.\n",
      "similar_items_recommendation is ready.\n",
      "n = 200\n",
      "als is ready.\n",
      "own is ready.\n",
      "similar_items_recommendation is ready.\n",
      "n = 500\n",
      "als is ready.\n",
      "own is ready.\n",
      "similar_items_recommendation is ready.\n"
     ]
    }
   ],
   "source": [
    "users_train = data_train_lvl_1['user_id'].tolist()\n",
    "users_valid = result_lvl_1['user_id'].tolist()\n",
    "new_users = list(set(users_valid) - set(users_train))\n",
    "all_users = list(set(users_valid) & set(users_train))\n",
    "result_lvl_1 = result_lvl_1[~result_lvl_1['user_id'].isin(new_users)]\n",
    "\n",
    "recommenders = [name for name, val in MainRecommender.__dict__.items() if callable(val)][-4:]\n",
    "n = [20, 50, 100, 200, 500]\n",
    "for l in n: \n",
    "    print(f'n = {l}')\n",
    "    for r in recommenders:\n",
    "        try:\n",
    "            model_name_col = r.replace('get_', '').replace('_recommendations', '')\n",
    "            result_lvl_1[model_name_col] = \\\n",
    "            result_lvl_1['user_id'].apply(lambda x: eval(f'recommender.{r}({x}, N={l})'))\n",
    "            result_lvl_1[model_name_col+'_score'] = \\\n",
    "            result_lvl_1.apply(lambda x: recall_at_k(x[model_name_col], x['actual'], k=l), axis=1).mean()\n",
    "            print(model_name_col, 'is ready.')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = [item for item in result_lvl_1.columns.tolist() if 'score' in item]\n",
    "result_lvl_1[score_columns].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAHJu3Z5C4Ju"
   },
   "source": [
    "### Задание 2.\n",
    "\n",
    "Обучите модель 2-ого уровня, при этом:\n",
    "    - Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
    "    - Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2\n",
    "    - Вырос ли precision@5, map@5, ndcg@5 при использовании двухуровневой модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZQcrch7C4Ju"
   },
   "outputs": [],
   "source": [
    "# add new user_feature (средний чек)\n",
    "basket_stat = user_features.merge(data, on='user_id', how='left')\n",
    "basket_stat = basket_stat.pivot_table(index='user_id', values=['basket_id', 'sales_value'], \n",
    "                                      aggfunc={'basket_id': 'count', 'sales_value': 'sum'})\n",
    "basket_stat = basket_stat['sales_value'] / basket_stat['basket_id']\n",
    "basket_stat = basket_stat.reset_index()\n",
    "basket_stat.rename(columns={0: 'avg_price'}, inplace=True)\n",
    "user_features = user_features.merge(basket_stat.reset_index(), on='user_id')\n",
    "del basket_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new user_feature (популярность = количество продаж)\n",
    "items_popularity = item_features.merge(data, on='item_id', how='left')\n",
    "items_popularity = items_popularity.pivot_table(index='item_id', values='quantity', aggfunc='sum')\n",
    "items_popularity = items_popularity.reset_index()\n",
    "items_popularity.rename(columns={'quantity': 'item_pop'}, inplace=True)\n",
    "item_features = item_features.merge(items_popularity, on='item_id')\n",
    "del items_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data_func):\n",
    "    # creating dataset for ranking\n",
    "    df_match_candidates = pd.DataFrame(data_func['user_id'].unique())\n",
    "    df_match_candidates.columns = ['user_id']\n",
    "    df_match_candidates = \\\n",
    "    df_match_candidates[df_match_candidates['user_id'].isin(data_train_lvl_1['user_id'].unique())]\n",
    "    df_match_candidates['candidates'] = \\\n",
    "    df_match_candidates['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=n))\n",
    "\n",
    "    df_items = \\\n",
    "    df_match_candidates.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    df_items.name = 'item_id'\n",
    "    df_match_candidates = df_match_candidates.drop('candidates', axis=1).join(df_items)\n",
    "\n",
    "    # Создаем трейн сет для ранжирования с учетом кандидатов с этапа 1\n",
    "    df_ranker_train = data_func[['user_id', 'item_id']].copy()\n",
    "    df_ranker_train['target'] = 1  # тут только покупки \n",
    "    df_ranker_train = df_match_candidates.merge(df_ranker_train, on=['user_id', 'item_id'], how='left')\n",
    "    df_ranker_train['target'].fillna(0, inplace= True)\n",
    "\n",
    "    # merging\n",
    "    df_ranker_train = df_ranker_train.merge(item_features, on='item_id', how='left')\n",
    "    df_ranker_train = df_ranker_train.merge(user_features, on='user_id', how='left')\n",
    "    \n",
    "    # train split\n",
    "    X = df_ranker_train.drop('target', axis=1)\n",
    "    y = df_ranker_train[['target']]\n",
    "    \n",
    "    return [X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing(data_train_lvl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[2:].tolist()\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')\n",
    "\n",
    "cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML\n",
    "lgb = LGBMClassifier(objective='binary',\n",
    "                     max_depth=8,\n",
    "                     n_estimators=300,\n",
    "                     learning_rate=0.05,\n",
    "                     categorical_column=cat_feats)\n",
    "\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "train_preds = lgb.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating\n",
    "df_ranker_predict = X_train.copy()\n",
    "df_ranker_predict['proba_item_purchase'] = train_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocessing(data_val_lvl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_ranker = X_test.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_eval_ranker.columns=['user_id', 'actual']\n",
    "result_eval_ranker.head(2)\n",
    "\n",
    "# get real target answers\n",
    "X_test_y = X_test.merge(y_test, right_index=True, left_index=True)\n",
    "y_test_unique = X_test_y[X_test_y['target']==1.0].groupby('user_id')['item_id'].unique().reset_index()\n",
    "y_test_unique.columns=['user_id', 'y_actual']\n",
    "y_test_unique.head(2)\n",
    "\n",
    "# add y_test as y_actual\n",
    "result_eval_ranker = result_eval_ranker.merge(y_test_unique, on='user_id', how='left').fillna(\"\").apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_ranker['own_rec'] = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating by precision@5\n",
    "def rerank(user_id):\n",
    "    return X_test[X_test['user_id']==user_id].sort_values('predict', ascending=False).head(5).item_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability predictions\n",
    "X_test[cat_feats] = X_test[cat_feats].astype('category')\n",
    "X_test['predict'] = lgb.predict_proba(X_test)[:, 1]\n",
    "X_test = X_test.sort_values(['user_id', 'predict'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_ranker['reranked_own_rec'] = result_eval_ranker['user_id'].apply(lambda user_id: rerank(user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_ranker.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_matcher = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: \n",
    "                                    precision_at_k(result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                          'own_rec'].squeeze(), \n",
    "                                                   result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                          'y_actual'].squeeze(), \n",
    "                                                   k=5)).mean()\n",
    "precision_ranked_matcher = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: \n",
    "                                    precision_at_k(result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                          'reranked_own_rec'].squeeze(), \n",
    "                                                   result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                          'y_actual'].squeeze(), \n",
    "                                                   k=5)).mean()\n",
    "\n",
    "print(f'precision@5 of 1lvl-model is {precision_matcher}\\nprecision@5 of 2lvl-model is {precision_ranked_matcher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_matcher = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: ap_k_2(result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                            'own_rec'].squeeze(), \n",
    "                                                     result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                            'y_actual'].squeeze(), \n",
    "                                                     k=5)).mean()\n",
    "map_ranked_matcher = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: ap_k_2(result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                            'reranked_own_rec'].squeeze(), \n",
    "                                                     result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                            'y_actual'].squeeze(), \n",
    "                                                     k=5)).mean()\n",
    "\n",
    "print(f'map@5 of 1lvl-model is {map_matcher}\\nmap@5 of 2lvl-model is {map_ranked_matcher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_matcher = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: \n",
    "                                    ndcg_at_k(result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                     'own_rec'].squeeze(), \n",
    "                                              result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                     'y_actual'].squeeze(), \n",
    "                                              k=5)).mean()\n",
    "ndcg_ranked_matcher = \\\n",
    "result_eval_ranker['user_id'].apply(lambda x: \n",
    "                                    ndcg_at_k(result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                     'reranked_own_rec'].squeeze(), \n",
    "                                              result_eval_ranker.loc[result_eval_ranker['user_id']==x, \n",
    "                                                                     'y_actual'].squeeze(), \n",
    "                                              k=5)).mean()\n",
    "\n",
    "print(f'ndcg@5 of 1lvl-model is {ndcg_matcher}\\nndcg@5 of 2lvl-model is {ndcg_ranked_matcher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (precision_ranked_matcher >= precision_matcher) & \\\n",
    "(map_ranked_matcher >= map_matcher) & \\\n",
    "(ndcg_ranked_matcher >= ndcg_matcher): \n",
    "    print('Ответ: Да вырос.')\n",
    "else:\n",
    "    print('Ответ: Нет, не вырос.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_webinar_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
